{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Honours Project - Fake News Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngit code:\\ngit add .\\ngit commit -m \"First commit\"\\ngit push origin master\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "git code:\n",
    "git add .\n",
    "git commit -m \"First commit\"\n",
    "git push origin master\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will be using the approach of CRISP-DM (Cross-industry standard process for data mining), which is a widely used process for knowledge discovery in data sets. \n",
    "The process encompasses several phases:\n",
    "\n",
    "    1. Business Understanding\n",
    "    2. Data Understanding\n",
    "    3. Data Preparation\n",
    "    4. Modeling\n",
    "    5. Evaluation\n",
    "    6. Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible data sets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/pontes/fake-news-sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real News: https://archive.ics.uci.edu/ml/datasets/News+Aggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://toolbox.google.com/datasetsearch/search?query=fake%20news&docid=sHyIQgRMuTsFH02AAAAAAA%3D%3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/hanselowski/athene_system/tree/master/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Goals/ Objectives &\n",
    "Success Criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 a) - Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "import string\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import sklearn.model_selection as ms\n",
    "#import sklearn.feature_extraction.text as text\n",
    "#import sklearn.naive_bayes as nb\n",
    "#from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.naive_bayes import MultinomialNB\n",
    "#from sklearn.naive_bayes import BernoulliNB\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 b) - Loading the Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0        8476                       You Can Smell Hillary’s Fear   \n",
       "1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2        3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3       10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4         875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4  It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/FakeNews-(balanced)/fake_or_real_news.csv\", encoding=\"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shocking! Michele Obama & Hillary Caught Glamorizing Date Rape Promoters First lady claims moral high ground while befriending rape-glorifying rappers Infowars.com - October 27, 2016 Comments \\nAlex Jones breaks down the complete hypocrisy of Michele Obama and Hillary Clinton attacking Trump for comments he made over a decade ago while The White House is hosting and promoting rappers who boast about date raping women and selling drugs in their music. \\nRappers who have been welcomed to the White House by the Obama’s include “Rick Ross,” who promotes drugging and raping woman in his song “U.O.N.E.O.” \\nWhile attacking Trump as a sexual predator, Michelle and Hillary have further mainstreamed the degradation of women through their support of so-called musicians who attempt to normalize rape. NEWSLETTER SIGN UP Get the latest breaking news & specials from Alex Jones and the Infowars Crew. Related Articles'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview of an FAKE article\n",
    "df.iloc[16,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hillary Clinton and Donald Trump made some inaccurate claims during an NBC “commander-in-chief” forum on military and veterans issues:\\n\\n• Clinton wrongly claimed Trump supported the war in Iraq after it started, while Trump was wrong, once again, in saying he was against the war before it started.\\n\\n•\\xa0Trump said that President Obama set a “certain date” for withdrawing troops from Iraq, when that date was set before Obama was sworn in.\\n\\n•\\xa0Trump said that Obama’s visits to China, Saudi Arabia and Cuba were “the first time in the history, the storied history of Air Force One” when “high officials” of a host country did not appear to greet the president. Not true.\\n\\n•\\xa0Clinton said that Trump supports privatizing the Veterans Health Administration. That’s false. Trump said he supports allowing veterans to seek care at either public or private hospitals.\\n\\n•\\xa0Trump said Clinton made “a terrible mistake on Libya” when she was secretary of State. But, at the time, Trump also supported U.S. action that led to the removal of Moammar Gadhafi from power.\\n\\n•\\xa0Trump cherry-picked Clinton’s words when he claimed Clinton said “vets are being treated, essentially, just fine.” Clinton had said the problems in the Department of Veterans Affairs were not as “widespread” as some Republicans claimed, but she went on to acknowledge problems, including the issue of wait times for doctors.\\n\\nThe forum, sponsored by NBC News and the Iraq and Afghanistan Veterans of America, was held Sept. 7 at the Intrepid Sea, Air & Space Museum in New York City. Today\\xa0show host Matt Lauer, and members of the military and veterans in the audience, questioned the candidates separately.\\n\\nTrump said he “was totally against the war in Iraq,” while Clinton claimed that he supported the Iraq War before and after it started. The facts don’t support either candidate’s strong assertions.\\n\\nOur review of Trump’s statements before and after the Iraq War started found no evidence that Trump opposed the war before it started. In fact, he expressed mild support for invading Iraq when asked about it on the Howard Stern radio show on Sept. 11, 2002 — about six months before the war started.\\n\\nStern asked Trump if he supported a war with Iraq, and Trump responded, “Yeah, I guess so.”\\n\\nIn the NBC commander in chief forum, Trump cited an Esquire article that appeared in August 2004 to show his opposition to the war. But that article appeared 17 months after the war started.\\n\\nAs for Clinton, who as a senator voted in October 2002 to authorize the war in Iraq, the Democratic nominee claimed that Trump “supported it before it happened, he supported it as it was happening and he is on record as supporting it after it happened.”\\n\\nBut just as there is no evidence that Trump opposed the Iraq War before it started, the Clinton campaign offered no evidence that Trump supported the war “after it happened.”\\n\\nThe Clinton campaign cited Trump’s interview on March 21, 2003, with Neil Cavuto of Fox Business just two days after the war started.\\n\\nCavuto asked Trump about the impact of the war on the stock market. Trump said the war “looks like a tremendous success from a military standpoint,” and he predicted the market will “go up like a rocket” after the war. But Cavuto does not ask Trump whether the U.S. should have gone to war with Iraq or whether he supports the war, and Trump doesn’t offer an opinion.\\n\\nAs early as July 2003, Trump expressed concern on Hardball with Chris Matthews\\xa0about money being spent in Iraq rather than in the U.S. Two months later, Trump told MSNBC’s Joe Scarborough, “I guess maybe if I had to do it, I would have fought terrorism but not necessarily Iraq.”\\n\\nClinton invited her audience to read Trump’s comments on the Iraq War. They can read our timeline, “Donald Trump and the Iraq War.”\\n\\nTrump said President Obama set a “certain date” for withdrawing troops from Iraq, but that date was actually set by President George W. Bush.\\n\\nNBC’s Matt Lauer asked Trump about his tendency to respond, when pushed for details on his military proposals, that he’s not going to give details because he wants to be “unpredictable.” Trump responded, “Absolutely,” and went on to criticize Obama for revealing the withdrawal date.\\n\\nAs we said then, Republicans and Democrats disagree on whether Obama or Bush is to blame for withdrawing all combat troops from Iraq at the end of 2011. But that date was set when Bush signed the Status of Forces Agreement on Dec. 14, 2008. It said: “All the United States Forces shall withdraw from all Iraqi territory no later than December 31, 2011.”\\n\\nIn the NBC forum, Trump also called the withdrawal of troops “a terrible decision.” As we’ve explained before, Condoleezza Rice, Bush’s secretary of State, later wrote that Bush wanted an agreement for a residual force to remain, but Iraqi Prime Minister Nouri al-Maliki objected.\\n\\nOnce Obama took office in January 2009, he had three years to renegotiate the deal, which his administration tried to do, to leave a residual American troop force. But Maliki still didn’t agree. Negotiations broke down in October 2011 over the issue of whether U.S. troops would be shielded from criminal prosecution by Iraqi authorities. Whether Obama did enough is a matter of opinion: His then defense secretary, Leon Panetta, later wrote that the president didn’t press hard enough for a deal. But some experts say Iraq was more closely aligned at the time with Iran and there wasn’t a deal to be made with Maliki.\\n\\nSo, both presidents had a role in the withdrawal of troops. But Trump wrongly said that Obama was the one who set a “certain date” for withdrawal and let U.S. enemies know about it, when that date was set before Obama was sworn in.\\n\\nIt’s worth noting that Trump said in a March 16, 2007, interview on CNN that the troops should be withdrawn quickly from Iraq.\\n\\nTrump said that Obama’s visits to China, Saudi Arabia and Cuba were “the first time in the history, the storied history of Air Force One” when “high officials” of a host country did not appear to greet the president.\\n\\nThat’s not true. Other presidents have encountered similar low-key greetings on foreign trips aboard the presidential aircraft.\\n\\nTrump referred to the fact that Cuba’s president, Raul Castro, did not greet Obama at the airport on his historic visit to Cuba in March, that Saudi Arabia’s King Salman did not meet Air Force One at the start of Obama’s trip to Riyadh in April, and he referred to China’s handling of the president’s arrival in Hangzhou last Saturday for a Group of 20 meeting.\\n\\nWhether or not those arrivals constituted snubs of a U.S. president as Trump claims is a matter of debate. But Trump is wrong on the facts when he claims it has not happened before. It has.\\n\\nIn 1984, for example, Ronald Reagan landed in Beijing and was received by China’s foreign minister rather than the president, whom he met only later. Similarly, on a 1985 trip to West Germany, Reagan was met by the foreign minister and not Chancellor Helmut Kohl.\\n\\nThese and other examples were dug up by our friend Glenn Kessler, the Washington Post‘s “Fact Checker,” who researched a Trump claim in April that Cuba’s and Saudi Arabia’s handling of Obama’s visits were “without precedent.” Kessler said of Trump, “once again he’s wrong, wrong, wrong.”\\n\\nKessler also noted that during Richard Nixon’s historic 1972 visit to China he was greeted at the airport by the country’s number two man, Premier Zhou Enlai. His boss, Chairman Mao, didn’t even agree to meet with Nixon until after he had arrived at a guest house.\\n\\nClinton said that her plan to overhaul the Veterans Health Administration would not include privatization, which she said Trump supports.\\n\\nBut Trump refuted that statement when it was his turn to discuss his plan to help veterans. “I would not do that,” Trump said, referring to Clinton’s claim that he supports privatization.\\n\\nTrump’s campaign published “The Goals Of Donald J. Trump’s Veterans Plan” on its website last October. It doesn’t call for the VA to be completely privatized.\\n\\nOne of the biggest changes that plan would make to the current VA health care system is allowing veterans to get care at any non-VA medical center that accepts Medicare.\\n\\n“Under a Trump Administration, all veterans eligible for VA health care can bring their veteran’s ID card to any doctor or care facility that accepts Medicare to get the care they need immediately,” the plan states.\\n\\n“The power to choose will stop the wait time backlogs and force the VA to improve and compete if the department wants to keep receiving veterans’ healthcare dollars,” the plan says.\\n\\nTrump’s proposal would seemingly go further than the Non-VA Medical Care Program, which allows eligible veterans to access care outside of the VA under certain circumstances, such as when VA medical centers cannot provide services. The program requires pre-approval for veterans to receive care at a non-VA facility in non-emergency situations.\\n\\nTrump’s proposal would also go further than the bipartisan Veterans Choice Act of 2014 that President Obama signed into law, creating a temporary program, separate from the Non-VA Medical Care Program, that allows eligible veterans to receive health care at a non-VA facility if they would have to wait more than 30 days for an appointment at a VA medical center, or if they live more than 40 miles from the nearest VA hospital.\\n\\nTrump stuck to the idea of allowing veterans to choose between public and private hospitals when he released his most recent “Ten Point Plan To Reform The VA” in July.\\n\\nPoint 10 of the plan says: “Mr. Trump will ensure every veteran has the choice to seek care at the VA or at a private service provider of their own choice. Under a Trump Administration, no veteran will die waiting for service.”\\n\\nTrump reinforced that part of his plan during the NBC News forum as well.\\n\\nTo be clear, Trump supports giving veterans a choice between VA hospitals and private ones. That’s not the same thing as supporting the complete privatization of the system that provides care to veterans.\\n\\nTrump criticized Clinton for making “a terrible mistake on Libya” when she was secretary of State. But, at the time, Trump also supported U.S. action that led to the removal of Moammar Gadhafi from power.\\n\\nTrump made his claim in response to a question posed by Lauer on whether Trump will be “prepared on Day One,” if elected president, to tackle “complex national security issues.”\\n\\nThis isn’t the first time Trump has ignored his past support for the U.S. intervention in Libya.\\n\\nDuring the 10th GOP debate, Trump said he had “never discussed that subject” when Sen. Ted Cruz called him out on supporting U.S. action in the country. But, as we wrote, Trump said in 2011 that the U.S. should go into Libya “on a humanitarian basis” and “knock [Gadhafi] out very quickly, very surgically, very effectively and save the lives.”\\n\\nTrump made that comment in a video posted to his YouTube channel in February 2011:\\n\\nEven though Trump now says Clinton’s support for intervention in Libya was a “terrible mistake,” it doesn’t change the fact that five years ago he supported Gadhafi’s removal.\\n\\nTrump twisted Clinton’s words when he claimed Clinton said “vets are being treated, essentially, just fine.” Clinton said the problems in the Department of Veterans Affairs were not as “widespread” as some Republican supporters of privatization of the VA claim, but she went on to acknowledge problems in the VA system — including the issue of wait times for doctors — and what she would do to address them.\\n\\nTrump highlighted the issue of wait times to see a doctor as “one of the big problems” in the VA, and then suggested Clinton doesn’t think the VA has problems.\\n\\nLauer interrupted, noting that Clinton “went on after that and laid out a litany of problems within the VA.”\\n\\nTrump insisted his version was accurate, adding, “I’m telling you … she said she was satisfied with what was going on in the Veterans Administration.”\\n\\nThat’s not accurate. The comments in question from Clinton came during an interview with MSNBC’s Rachel Maddow on Oct. 23, 2015. Maddow asked about talk among some Republicans of abolishing the VA and privatizing it. “The reason they are able to propose something that radical is because the problems at the VA seem so intractable,” Maddow said.\\n\\nMaddow asked if Clinton had any “new ideas for trying to fix” the VA. Here was Clinton’s response, with the part Trump is referring to in bold.\\n\\nClinton accused Republicans of underfunding the VA because they “want it to fail” so they can privatize it.\\n\\nClinton added, “But we have to be more creative about trying to fix the problems that are the legitimate concern, so that we can try to stymie the Republican assault.”\\n\\nIndeed, the Clinton campaign website states that Clinton wants to “fundamentally reform veterans’ health care to ensure access to timely and high quality care.” The campaign says Clinton “was outraged by the recent scandals at the VA, and as president, she will demand accountability and performance from VA leadership.” The site specifically mentions Clinton’s dissatisfaction that “[m]any veterans have to wait an unacceptably long time to see a doctor or to process disability claims and appeals” and promises she will “[b]uild a 21st-century Department of Veterans Affairs to deliver world-class care.”\\n\\nTrump cherry-picked the part of Clinton’s response that said problems in the VA have “not been as widespread as it has been made out to be,” to make the blanket claim that Clinton is “satisfied with what was going on in the Veterans Administration” and that “vets are being treated, essentially, just fine.” But Trump is leaving out the parts of Clinton’s answer that acknowledged problems in the VA — including the wait time issue Trump highlighted as one of his biggest concerns.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preview of an REAL article\n",
    "df.iloc[8,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of       Unnamed: 0                                              title  \\\n",
       "0           8476                       You Can Smell Hillary’s Fear   \n",
       "1          10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2           3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3          10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4            875   The Battle of New York: Why This Primary Matters   \n",
       "5           6903                                        Tehran, USA   \n",
       "6           7341  Girl Horrified At What She Watches Boyfriend D...   \n",
       "7             95                  ‘Britain’s Schindler’ Dies at 106   \n",
       "8           4869  Fact check: Trump and Clinton at the 'commande...   \n",
       "9           2909  Iran reportedly makes new push for uranium con...   \n",
       "10          1357  With all three Clintons in Iowa, a glimpse at ...   \n",
       "11           988  Donald Trump’s Shockingly Weak Delegate Game S...   \n",
       "12          7041  Strong Solar Storm, Tech Risks Today | S0 News...   \n",
       "13          7623       10 Ways America Is Preparing for World War 3   \n",
       "14          1571                   Trump takes on Cruz, but lightly   \n",
       "15          4739                         How women lead differently   \n",
       "16          7737  Shocking! Michele Obama & Hillary Caught Glamo...   \n",
       "17          8716  Hillary Clinton in HUGE Trouble After America ...   \n",
       "18          3304  What's in that Iran bill that Obama doesn't like?   \n",
       "19          3078  The 1 chart that explains everything you need ...   \n",
       "20          2517  The slippery slope to Trump’s proposed ban on ...   \n",
       "21         10348  Episode #160 – SUNDAY WIRE: ‘Hail to the Deplo...   \n",
       "22           778  Hillary Clinton Makes A Bipartisan Appeal on S...   \n",
       "23          3300  New Senate majority leader’s main goal for GOP...   \n",
       "24          6155              ‘Inferno’ and the Overpopulation Myth   \n",
       "25           636  Anti-Trump forces seek last-ditch delegate revolt   \n",
       "26           755  Sanders Trounces Clinton in W. Va. -- But Will...   \n",
       "27           626  Donald Trump Is Changing His Campaign Slogan t...   \n",
       "28           691  Pure chaos: Donald Trump’s campaign management...   \n",
       "29          5743  Syrian War Report – November 1, 2016: Syrian M...   \n",
       "...          ...                                                ...   \n",
       "6305        6457  Colin Kaepernick hosts ‘Know Your Rights’ camp...   \n",
       "6306        7030  Wikileaks Emails Disclose Aliens Linked to Vat...   \n",
       "6307        9013  US abstains from UN vote calling for end to Cu...   \n",
       "6308        9509  West Ham fans laud aerodynamic properties of n...   \n",
       "6309        3825      How the Obama White House runs foreign policy   \n",
       "6310        4515  ISIS claims responsibility for Garland, Texas,...   \n",
       "6311        2747  The “blame the left” crew: What the right’s ne...   \n",
       "6312        6516  ADHD NATION: How Big Pharma Created the ADHD E...   \n",
       "6313        9636  Donald Trump claims the election will be 'rigg...   \n",
       "6314        7398  REPORT: Dirty Reporter Blackmails Montel… Help...   \n",
       "6315        3717  Police Arrest Suspect In Charleston Church Sho...   \n",
       "6316        5205  Donald Trump’s collapse was caused by one big ...   \n",
       "6317        6696  FINA suspends Russian swimmer for 8 years over...   \n",
       "6318        7991  BREAKING : Hillary Campaign Manager Deletes hi...   \n",
       "6319        1303  Why Ted Cruz Has the Most to Lose in New Hamps...   \n",
       "6320        9051  “Nothing Good Can Come of This Election”–and T...   \n",
       "6321       10200   List of Republicans opposing Trump | OffGuardian   \n",
       "6322       10009  Putin: Use of 'mythical' Russian military thre...   \n",
       "6323        4214  Bernie Sanders says private meeting with Pope ...   \n",
       "6324        2316  Alabama Lawmaker: Same-Sex Couples Don’t Deser...   \n",
       "6325        8411  Will the Media Reset After the Election or Are...   \n",
       "6326        6143  DOJ COMPLAINT: Comey Under Fire Over Partisan ...   \n",
       "6327        3262  GOP Senator David Perdue Jokes About Praying f...   \n",
       "6328        9337  Radio Derb Is On The Air–Leonardo And Brazil’s...   \n",
       "6329        8737  Assange claims ‘crazed’ Clinton campaign tried...   \n",
       "6330        4490  State Department says it can't find emails fro...   \n",
       "6331        8062  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...   \n",
       "6332        8622  Anti-Trump Protesters Are Tools of the Oligarc...   \n",
       "6333        4021  In Ethiopia, Obama seeks progress on peace, se...   \n",
       "6334        4330  Jeb Bush Is Suddenly Attacking Trump. Here's W...   \n",
       "\n",
       "                                                   text label  \n",
       "0     Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "1     Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "2     U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "3     — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "4     It's primary day in New York and front-runners...  REAL  \n",
       "5       \\nI’m not an immigrant, but my grandparents ...  FAKE  \n",
       "6     Share This Baylee Luciani (left), Screenshot o...  FAKE  \n",
       "7     A Czech stockbroker who saved more than 650 Je...  REAL  \n",
       "8     Hillary Clinton and Donald Trump made some ina...  REAL  \n",
       "9     Iranian negotiators reportedly have made a las...  REAL  \n",
       "10    CEDAR RAPIDS, Iowa — “I had one of the most wo...  REAL  \n",
       "11    Donald Trump’s organizational problems have go...  REAL  \n",
       "12    Click Here To Learn More About Alexandra's Per...  FAKE  \n",
       "13    October 31, 2016 at 4:52 am \\nPretty factual e...  FAKE  \n",
       "14    Killing Obama administration rules, dismantlin...  REAL  \n",
       "15    As more women move into high offices, they oft...  REAL  \n",
       "16    Shocking! Michele Obama & Hillary Caught Glamo...  FAKE  \n",
       "17    0 \\nHillary Clinton has barely just lost the p...  FAKE  \n",
       "18    Washington (CNN) For months, the White House a...  REAL  \n",
       "19    While paging through Pew's best data visualiza...  REAL  \n",
       "20    With little fanfare this fall, the New York de...  REAL  \n",
       "21    November 13, 2016 By 21wire Leave a Comment \\n...  FAKE  \n",
       "22    Hillary Clinton told a Staten Island crowd tod...  REAL  \n",
       "23    Mitch McConnell has an unusual admonition for ...  REAL  \n",
       "24    Mises.org November 1, 2016 Inferno is a great ...  FAKE  \n",
       "25    Washington (CNN) The faction of the GOP that i...  REAL  \n",
       "26    Meanwhile, Democrat Bernie Sanders picked up m...  REAL  \n",
       "27    After a week of nonstop criticism from Democra...  REAL  \n",
       "28    If you want a glimpse into a presidential cand...  REAL  \n",
       "29    Syrian War Report – October 31, 2016: Al-Nusra...  FAKE  \n",
       "...                                                 ...   ...  \n",
       "6305  Print \\n[Ed. – Now teaching the gospel of raci...  FAKE  \n",
       "6306  Sound too “strange” to be true? We have proof!...  FAKE  \n",
       "6307  US abstains from UN vote calling for end to Cu...  FAKE  \n",
       "6308  Tuesday 1 November 2016 by Formelia Alberthine...  FAKE  \n",
       "6309  When Susan E. Rice took over as President Obam...  REAL  \n",
       "6310  (CNN) ISIS has claimed responsibility for the ...  REAL  \n",
       "6311  It was inevitable that liberals would end up b...  REAL  \n",
       "6312  By Kalee Brown\\nWhile I was at university, man...  FAKE  \n",
       "6313  Email \\nDonald Trump is again riling up his vo...  FAKE  \n",
       "6314  BREAKING: Trump Jumps in FL, Takes 4 Point Lea...  FAKE  \n",
       "6315  Police in Charleston, S.C., say a man they sus...  REAL  \n",
       "6316  Silver of FiveThirtyEight.com has laid out fou...  REAL  \n",
       "6317  This post was originally published on this sit...  FAKE  \n",
       "6318  BREAKING : Hillary Campaign Manager Deletes hi...  FAKE  \n",
       "6319  Ted Cruz took first prize in the Iowa caucuses...  REAL  \n",
       "6320  Posted on November 4, 2016 by Charles Hugh Smi...  FAKE  \n",
       "6321  Charlie Baker , Massachusetts (2015–present)[3...  FAKE  \n",
       "6322  vladimir putin , Valdai , sochi , RBTH Daily R...  FAKE  \n",
       "6323  ROME —  U.S. Democratic presidential candidate...  REAL  \n",
       "6324  Most conservatives who oppose marriage equalit...  REAL  \n",
       "6325  Written by Peter Van Buren   venerable New Yor...  FAKE  \n",
       "6326  DOJ COMPLAINT: Comey Under Fire Over Partisan ...  FAKE  \n",
       "6327  The freshman senator from Georgia quoted scrip...  REAL  \n",
       "6328                                                     FAKE  \n",
       "6329  Julian Assange has claimed the Hillary Clinton...  FAKE  \n",
       "6330  The State Department told the Republican Natio...  REAL  \n",
       "6331  The ‘P’ in PBS Should Stand for ‘Plutocratic’ ...  FAKE  \n",
       "6332   Anti-Trump Protesters Are Tools of the Oligar...  FAKE  \n",
       "6333  ADDIS ABABA, Ethiopia —President Obama convene...  REAL  \n",
       "6334  Jeb Bush Is Suddenly Attacking Trump. Here's W...  REAL  \n",
       "\n",
       "[6335 rows x 4 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'title', 'text', 'label']\n"
     ]
    }
   ],
   "source": [
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "REAL    3171\n",
       "FAKE    3164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set seems to be well balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0     int64\n",
       "title         object\n",
       "text          object\n",
       "label         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that \"Unnamed: 0\" is the index since it only contains numbers. The column will be checked for duplicates to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(any(df[\"Unnamed: 0\"].duplicated()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 a) - General Polishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename \"Unnamed: 0\" and make it the index of the data frame\n",
    "df.columns = [\"index\", \"title\", \"text\", \"label\"]\n",
    "df.set_index(\"index\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text label  \n",
       "index                                                           \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...  REAL  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n",
       "875    It's primary day in New York and front-runners...  REAL  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order by index\n",
    "df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Study: women had to drive 4 times farther afte...</td>\n",
       "      <td>Ever since Texas laws closed about half of the...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump, Clinton clash in dueling DC speeches</td>\n",
       "      <td>Donald Trump and Hillary Clinton, now at the s...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>As Reproductive Rights Hang In The Balance, De...</td>\n",
       "      <td>WASHINGTON -- Forty-three years after the Supr...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Despite Constant Debate, Americans' Abortion O...</td>\n",
       "      <td>It's been a big week for abortion news.\\n\\nCar...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Obama Argues Against Goverment Shutdown Over P...</td>\n",
       "      <td>President Barack Obama said Saturday night tha...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "2      Study: women had to drive 4 times farther afte...   \n",
       "3            Trump, Clinton clash in dueling DC speeches   \n",
       "5      As Reproductive Rights Hang In The Balance, De...   \n",
       "6      Despite Constant Debate, Americans' Abortion O...   \n",
       "7      Obama Argues Against Goverment Shutdown Over P...   \n",
       "\n",
       "                                                    text label  \n",
       "index                                                           \n",
       "2      Ever since Texas laws closed about half of the...  REAL  \n",
       "3      Donald Trump and Hillary Clinton, now at the s...  REAL  \n",
       "5      WASHINGTON -- Forty-three years after the Supr...  REAL  \n",
       "6      It's been a big week for abortion news.\\n\\nCar...  REAL  \n",
       "7      President Barack Obama said Saturday night tha...  REAL  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    2,     3,     5,     6,     7,     9,    10,    12,    14,\n",
       "               16,\n",
       "            ...\n",
       "            10543, 10545, 10546, 10547, 10548, 10549, 10551, 10553, 10555,\n",
       "            10557],\n",
       "           dtype='int64', name='index', length=6335)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index seems to skip some numbers, for example 8 and 11. The index will be properly assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index'] = df.reset_index().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Study: women had to drive 4 times farther afte...</td>\n",
       "      <td>Ever since Texas laws closed about half of the...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump, Clinton clash in dueling DC speeches</td>\n",
       "      <td>Donald Trump and Hillary Clinton, now at the s...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Reproductive Rights Hang In The Balance, De...</td>\n",
       "      <td>WASHINGTON -- Forty-three years after the Supr...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Despite Constant Debate, Americans' Abortion O...</td>\n",
       "      <td>It's been a big week for abortion news.\\n\\nCar...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obama Argues Against Goverment Shutdown Over P...</td>\n",
       "      <td>President Barack Obama said Saturday night tha...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "0      Study: women had to drive 4 times farther afte...   \n",
       "1            Trump, Clinton clash in dueling DC speeches   \n",
       "2      As Reproductive Rights Hang In The Balance, De...   \n",
       "3      Despite Constant Debate, Americans' Abortion O...   \n",
       "4      Obama Argues Against Goverment Shutdown Over P...   \n",
       "\n",
       "                                                    text label  \n",
       "index                                                           \n",
       "0      Ever since Texas laws closed about half of the...  REAL  \n",
       "1      Donald Trump and Hillary Clinton, now at the s...  REAL  \n",
       "2      WASHINGTON -- Forty-three years after the Supr...  REAL  \n",
       "3      It's been a big week for abortion news.\\n\\nCar...  REAL  \n",
       "4      President Barack Obama said Saturday night tha...  REAL  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"index\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the data contains several characters like \\n or \\a. They will be removed from the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 b) - Normalising The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u0007 abc\n"
     ]
    }
   ],
   "source": [
    "# the function strip() will be used to remove those characters\n",
    "# Example:\n",
    "s = \"\\n \\a abc \\n \\n\"\n",
    "print(s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Car\n"
     ]
    }
   ],
   "source": [
    "s = \"\\n\\nCar\"\n",
    "print(s.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since some characters are part of the string, they have to be removed with the replace function\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\"\\t\", \"\"))\n",
    "#df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\"\\x\", \"\"))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\"\\xa0\", \"\"))\n",
    "\n",
    "df[\"title\"] = df[\"title\"].apply(lambda x: x.replace(\"\\n\", \"\"))\n",
    "df[\"title\"] = df[\"title\"].apply(lambda x: x.replace(\"\\t\", \"\"))\n",
    "#df[\"title\"] = df[\"title\"].apply(lambda x: x.replace(\"\\x\", \"\"))\n",
    "df[\"title\"] = df[\"title\"].apply(lambda x: x.replace(\"\\xa0\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Study: women had to drive 4 times farther afte...</td>\n",
       "      <td>Ever since Texas laws closed about half of the...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trump, Clinton clash in dueling DC speeches</td>\n",
       "      <td>Donald Trump and Hillary Clinton, now at the s...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As Reproductive Rights Hang In The Balance, De...</td>\n",
       "      <td>WASHINGTON -- Forty-three years after the Supr...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Despite Constant Debate, Americans' Abortion O...</td>\n",
       "      <td>It's been a big week for abortion news.Carly F...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Obama Argues Against Goverment Shutdown Over P...</td>\n",
       "      <td>President Barack ObamasaidSaturday night that ...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "0      Study: women had to drive 4 times farther afte...   \n",
       "1            Trump, Clinton clash in dueling DC speeches   \n",
       "2      As Reproductive Rights Hang In The Balance, De...   \n",
       "3      Despite Constant Debate, Americans' Abortion O...   \n",
       "4      Obama Argues Against Goverment Shutdown Over P...   \n",
       "\n",
       "                                                    text label  \n",
       "index                                                           \n",
       "0      Ever since Texas laws closed about half of the...  REAL  \n",
       "1      Donald Trump and Hillary Clinton, now at the s...  REAL  \n",
       "2      WASHINGTON -- Forty-three years after the Supr...  REAL  \n",
       "3      It's been a big week for abortion news.Carly F...  REAL  \n",
       "4      President Barack ObamasaidSaturday night that ...  REAL  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to remove punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(string.punctuation, \"\"))\n",
    "#df[\"title\"] = df[\"title\"].apply(lambda x: x.replace(string.punctuation, \"\"))\n",
    "\n",
    "df[\"title\"] = df[\"title\"].str.replace(\"[{}]\".format(string.punctuation), \"\")\n",
    "df[\"text\"] = df[\"text\"].str.replace(\"[{}]\".format(string.punctuation), \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert every word to lower case - normalising case\n",
    "df[\"title\"] = df[\"title\"].str.lower()\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "df[\"label\"] = df[\"label\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>study women had to drive 4 times farther after...</td>\n",
       "      <td>ever since texas laws closed about half of the...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump clinton clash in dueling dc speeches</td>\n",
       "      <td>donald trump and hillary clinton now at the st...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as reproductive rights hang in the balance deb...</td>\n",
       "      <td>washington  fortythree years after the supreme...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despite constant debate americans abortion opi...</td>\n",
       "      <td>its been a big week for abortion newscarly fio...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama argues against goverment shutdown over p...</td>\n",
       "      <td>president barack obamasaidsaturday night that ...</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "0      study women had to drive 4 times farther after...   \n",
       "1             trump clinton clash in dueling dc speeches   \n",
       "2      as reproductive rights hang in the balance deb...   \n",
       "3      despite constant debate americans abortion opi...   \n",
       "4      obama argues against goverment shutdown over p...   \n",
       "\n",
       "                                                    text label  \n",
       "index                                                           \n",
       "0      ever since texas laws closed about half of the...  real  \n",
       "1      donald trump and hillary clinton now at the st...  real  \n",
       "2      washington  fortythree years after the supreme...  real  \n",
       "3      its been a big week for abortion newscarly fio...  real  \n",
       "4      president barack obamasaidsaturday night that ...  real  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally the labels will be converted to binary values: 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"label\"] = df[\"label\"].apply(lambda x: x.replace(\"real\", 0))\n",
    "#df[\"label\"] = df[\"label\"].apply(lambda x: x.replace(\"fake\", 1))\n",
    "\n",
    "df[\"label\"] = df[\"label\"].replace(to_replace=[\"real\", \"fake\"], value=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>study women had to drive 4 times farther after...</td>\n",
       "      <td>ever since texas laws closed about half of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump clinton clash in dueling dc speeches</td>\n",
       "      <td>donald trump and hillary clinton now at the st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as reproductive rights hang in the balance deb...</td>\n",
       "      <td>washington  fortythree years after the supreme...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despite constant debate americans abortion opi...</td>\n",
       "      <td>its been a big week for abortion newscarly fio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama argues against goverment shutdown over p...</td>\n",
       "      <td>president barack obamasaidsaturday night that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "0      study women had to drive 4 times farther after...   \n",
       "1             trump clinton clash in dueling dc speeches   \n",
       "2      as reproductive rights hang in the balance deb...   \n",
       "3      despite constant debate americans abortion opi...   \n",
       "4      obama argues against goverment shutdown over p...   \n",
       "\n",
       "                                                    text  label  \n",
       "index                                                            \n",
       "0      ever since texas laws closed about half of the...      0  \n",
       "1      donald trump and hillary clinton now at the st...      0  \n",
       "2      washington  fortythree years after the supreme...      0  \n",
       "3      its been a big week for abortion newscarly fio...      0  \n",
       "4      president barack obamasaidsaturday night that ...      0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step stopwords such as \"the\" or \"a\" will be removed since they do not contribute to a deeper meaning of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "\n",
    "#function that tokenises words and removes stop words, punctuation and non alphanumerical characters in a sentence\n",
    "def func_normalise(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    #print(tokens)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    stop_words.add(\"n't\")\n",
    "    stop_words.add(\"nt\")\n",
    "    stop_words.add(\"u\")\n",
    "    \n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    \n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    \n",
    "    new_sentence = [w for w in words if not w in stop_words] \n",
    "            \n",
    "    new_sentence_str = \" \".join(new_sentence)\n",
    "    \n",
    "    return new_sentence_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ever since texas laws closed half'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing the function\n",
    "func_normalise(\"ever ? since hasn't the / texa*s laws closed about half of the where didn't\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the above function will be applied to the data in order to normalise it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"title\"].apply(func_normalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(func_normalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>study women drive times farther texas laws clo...</td>\n",
       "      <td>ever since texas laws closed half states abort...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump clinton clash dueling dc speeches</td>\n",
       "      <td>donald trump hillary clinton starting line gen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reproductive rights hang balance debate modera...</td>\n",
       "      <td>washington fortythree years supreme court esta...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despite constant debate americans abortion opi...</td>\n",
       "      <td>big week abortion newscarly fiorinas passionat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama argues goverment shutdown planned parent...</td>\n",
       "      <td>president barack obamasaidsaturday night congr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "0      study women drive times farther texas laws clo...   \n",
       "1                trump clinton clash dueling dc speeches   \n",
       "2      reproductive rights hang balance debate modera...   \n",
       "3      despite constant debate americans abortion opi...   \n",
       "4      obama argues goverment shutdown planned parent...   \n",
       "\n",
       "                                                    text  label  \n",
       "index                                                            \n",
       "0      ever since texas laws closed half states abort...      0  \n",
       "1      donald trump hillary clinton starting line gen...      0  \n",
       "2      washington fortythree years supreme court esta...      0  \n",
       "3      big week abortion newscarly fiorinas passionat...      0  \n",
       "4      president barack obamasaidsaturday night congr...      0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the above example the text data has been (successfully) normalised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 c) - Stemming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing words to their root. For example, \"playing\" and \"played\" reduce to the stem \"play\". Therefore stemming helps with reducing the vocabulary and allows to focus on the sense of a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.stem.porter import PorterStemmer\n",
    "#according to the nltk website the snowballstemmer is better than the \"original\" porter stemmer\n",
    "#https://www.nltk.org/howto/stem.html\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#function that stems words in a sentence\n",
    "def func_stem(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    snowball_stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed_sentence = [snowball_stemmer.stem(word) for word in tokens]\n",
    "    stemmed_sentence_str = \" \".join(stemmed_sentence)\n",
    "    return stemmed_sentence_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play player play play play'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "func_stem(\"playing player play played plays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"title\"].apply(func_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(func_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studi women drive time farther texa law close ...</td>\n",
       "      <td>ever sinc texa law close half state abort clin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump clinton clash duel dc speech</td>\n",
       "      <td>donald trump hillari clinton start line genera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reproduct right hang balanc debat moder drop ball</td>\n",
       "      <td>washington fortythre year suprem court establi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despit constant debat american abort opinion r...</td>\n",
       "      <td>big week abort newscar fiorina passion inaccur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama argu gover shutdown plan parenthood</td>\n",
       "      <td>presid barack obamasaidsaturday night congress...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "0      studi women drive time farther texa law close ...   \n",
       "1                     trump clinton clash duel dc speech   \n",
       "2      reproduct right hang balanc debat moder drop ball   \n",
       "3      despit constant debat american abort opinion r...   \n",
       "4              obama argu gover shutdown plan parenthood   \n",
       "\n",
       "                                                    text  label  \n",
       "index                                                            \n",
       "0      ever sinc texa law close half state abort clin...      0  \n",
       "1      donald trump hillari clinton start line genera...      0  \n",
       "2      washington fortythre year suprem court establi...      0  \n",
       "3      big week abort newscar fiorina passion inaccur...      0  \n",
       "4      presid barack obamasaidsaturday night congress...      0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 d) - Lemmatising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to literature lemmatising and stemming words is similar. However, stemming tries to cut off endings of words whereas lemmatising compares them to other words. To test whether lemmatising makes a difference in accuracy it will be implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\"\"\"\n",
    "\n",
    "def func_lemmatise(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    lemmatiser = nltk.WordNetLemmatizer()\n",
    "    lemmatised_sentence = [lemmatiser.lemmatize(word) for word in tokens]\n",
    "    lemmatised_sentence_str = \" \".join(lemmatised_sentence)\n",
    "    return lemmatised_sentence_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'playing player play played play'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "func_lemmatise(\"playing player play played plays\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title\"] = df[\"title\"].apply(func_lemmatise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(func_lemmatise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>studi woman drive time farther texa law close ...</td>\n",
       "      <td>ever sinc texa law close half state abort clin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trump clinton clash duel dc speech</td>\n",
       "      <td>donald trump hillari clinton start line genera...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>reproduct right hang balanc debat moder drop ball</td>\n",
       "      <td>washington fortythre year suprem court establi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>despit constant debat american abort opinion r...</td>\n",
       "      <td>big week abort newscar fiorina passion inaccur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama argu gover shutdown plan parenthood</td>\n",
       "      <td>presid barack obamasaidsaturday night congress...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "index                                                      \n",
       "0      studi woman drive time farther texa law close ...   \n",
       "1                     trump clinton clash duel dc speech   \n",
       "2      reproduct right hang balanc debat moder drop ball   \n",
       "3      despit constant debat american abort opinion r...   \n",
       "4              obama argu gover shutdown plan parenthood   \n",
       "\n",
       "                                                    text  label  \n",
       "index                                                            \n",
       "0      ever sinc texa law close half state abort clin...      0  \n",
       "1      donald trump hillari clinton start line genera...      0  \n",
       "2      washington fortythre year suprem court establi...      0  \n",
       "3      big week abort newscar fiorina passion inaccur...      0  \n",
       "4      presid barack obamasaidsaturday night congress...      0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 e) - TF-IDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since ML algorithms require numerical data as input instead of text, the text will be vectorised using the TF-IDF method, which stands for term frequency - inverse document frequency. TF-IDF is measure of orginiality of a word by comparing the number of times a word appears in a doc with the number of docs the words appears in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove arabian characters etc. Maybe activate them later?\n",
    "df[\"title\"] = df[\"title\"].replace(\"[^a-zA-Z0-9 ]\", \"\", regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(df[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aap',\n",
       " 'abandon',\n",
       " 'abbi',\n",
       " 'abc',\n",
       " 'abcwapo',\n",
       " 'abduct',\n",
       " 'abdullah',\n",
       " 'abedin',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'abnorm',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'abort',\n",
       " 'abortionrevers',\n",
       " 'abridg',\n",
       " 'abroad',\n",
       " 'abrog',\n",
       " 'absenc',\n",
       " 'absente',\n",
       " 'absolut',\n",
       " 'abstain',\n",
       " 'absurd',\n",
       " 'abu',\n",
       " 'abus',\n",
       " 'abyss',\n",
       " 'aca',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accur',\n",
       " 'accus',\n",
       " 'acela',\n",
       " 'acheron',\n",
       " 'achiev',\n",
       " 'ackbar',\n",
       " 'acknowledg',\n",
       " 'aclu',\n",
       " 'acquir',\n",
       " 'acquisit',\n",
       " 'acquit',\n",
       " 'acquitt',\n",
       " 'acr',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'activist',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'acupunctur',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'adderal',\n",
       " 'addict',\n",
       " 'addictionher',\n",
       " 'address',\n",
       " 'adelson',\n",
       " 'adequ',\n",
       " 'adhd',\n",
       " 'adhm',\n",
       " 'adjust',\n",
       " 'admin',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admit',\n",
       " 'adopt',\n",
       " 'ador',\n",
       " 'adpr',\n",
       " 'adpresnet',\n",
       " 'adult',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'advert',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'advisor',\n",
       " 'advoc',\n",
       " 'aerodynam',\n",
       " 'afar',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affili',\n",
       " 'affirm',\n",
       " 'afford',\n",
       " 'affront',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'aficionado',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanamerican',\n",
       " 'aftermath',\n",
       " 'aftershock',\n",
       " 'ag',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggress',\n",
       " 'aggro',\n",
       " 'agit',\n",
       " 'agn',\n",
       " 'ago',\n",
       " 'agoni',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'agricultur',\n",
       " 'agropoison',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aig',\n",
       " 'ail',\n",
       " 'aim',\n",
       " 'air',\n",
       " 'airbnb',\n",
       " 'aircraft',\n",
       " 'airman',\n",
       " 'airplan',\n",
       " 'airport',\n",
       " 'airstrik',\n",
       " 'akbar',\n",
       " 'al',\n",
       " 'alabadi',\n",
       " 'alabama',\n",
       " 'alarm',\n",
       " 'alarmist',\n",
       " 'alasdair',\n",
       " 'alaska',\n",
       " 'alassad',\n",
       " 'albert',\n",
       " 'alberto',\n",
       " 'albright',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'aleppo',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alfatah',\n",
       " 'ali',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'align',\n",
       " 'alist',\n",
       " 'alito',\n",
       " 'aliv',\n",
       " 'allah',\n",
       " 'allahu',\n",
       " 'allamerican',\n",
       " 'allay',\n",
       " 'alleg',\n",
       " 'allegi',\n",
       " 'allen',\n",
       " 'alli',\n",
       " 'allianc',\n",
       " 'allin',\n",
       " 'alloc',\n",
       " 'allout',\n",
       " 'allow',\n",
       " 'allpay',\n",
       " 'alltim',\n",
       " 'alltoofamiliar',\n",
       " 'almost',\n",
       " 'alnusra',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'aloof',\n",
       " 'alphabet',\n",
       " 'alqaeda',\n",
       " 'alreadi',\n",
       " 'alreadyflag',\n",
       " 'also',\n",
       " 'alsoran',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'altmarket',\n",
       " 'altright',\n",
       " 'altruist',\n",
       " 'alway',\n",
       " 'amaz',\n",
       " 'amazinglook',\n",
       " 'ambassador',\n",
       " 'ambit',\n",
       " 'ambival',\n",
       " 'ambul',\n",
       " 'ambush',\n",
       " 'ambushstyl',\n",
       " 'ame',\n",
       " 'amend',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'ami',\n",
       " 'amid',\n",
       " 'amish',\n",
       " 'ammo',\n",
       " 'ammon',\n",
       " 'ammosexu',\n",
       " 'amnesti',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amphibi',\n",
       " 'amtrak',\n",
       " 'amur',\n",
       " 'amurexit',\n",
       " 'amus',\n",
       " 'anaheim',\n",
       " 'analysi',\n",
       " 'analyst',\n",
       " 'anarchi',\n",
       " 'anarchist',\n",
       " 'anastasia',\n",
       " 'anatomi',\n",
       " 'anbar',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'anderson',\n",
       " 'andes',\n",
       " 'andrew',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angelina',\n",
       " 'anger',\n",
       " 'anglin',\n",
       " 'angri',\n",
       " 'angriest',\n",
       " 'anim',\n",
       " 'animos',\n",
       " 'ankl',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annihil',\n",
       " 'anniversari',\n",
       " 'annot',\n",
       " 'announc',\n",
       " 'annual',\n",
       " 'annul',\n",
       " 'anonym',\n",
       " 'anot',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antarct',\n",
       " 'antarctica',\n",
       " 'anthem',\n",
       " 'anthoni',\n",
       " 'anthropecen',\n",
       " 'anti',\n",
       " 'antiaircraft',\n",
       " 'antibiot',\n",
       " 'antic',\n",
       " 'anticip',\n",
       " 'anticlinton',\n",
       " 'anticommunist',\n",
       " 'anticorrupt',\n",
       " 'antidepress',\n",
       " 'antiestablish',\n",
       " 'antifamin',\n",
       " 'antigovern',\n",
       " 'antigovt',\n",
       " 'antihillari',\n",
       " 'antiiran',\n",
       " 'antiiraq',\n",
       " 'antiisi',\n",
       " 'antiislam',\n",
       " 'antiisrael',\n",
       " 'antijihad',\n",
       " 'antilgbt',\n",
       " 'antimalaria',\n",
       " 'antimissil',\n",
       " 'antimuhammad',\n",
       " 'antimuslim',\n",
       " 'antiparticl',\n",
       " 'antiplan',\n",
       " 'antipoverti',\n",
       " 'antiqu',\n",
       " 'antirussia',\n",
       " 'antirussian',\n",
       " 'antisemit',\n",
       " 'antisex',\n",
       " 'antitank',\n",
       " 'antiterror',\n",
       " 'antithet',\n",
       " 'antitrump',\n",
       " 'antiunion',\n",
       " 'antivax',\n",
       " 'antiwar',\n",
       " 'antonin',\n",
       " 'antonio',\n",
       " 'anxieti',\n",
       " 'anxious',\n",
       " 'anybodi',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'ao',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartheid',\n",
       " 'api',\n",
       " 'apocalyps',\n",
       " 'apocalypt',\n",
       " 'apolog',\n",
       " 'apologis',\n",
       " 'apologistinchief',\n",
       " 'apost',\n",
       " 'app',\n",
       " 'appal',\n",
       " 'appar',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appeas',\n",
       " 'appl',\n",
       " 'applebe',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'apprentic',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'april',\n",
       " 'aqutru',\n",
       " 'ar',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabian',\n",
       " 'arc',\n",
       " 'archil',\n",
       " 'architect',\n",
       " 'arctic',\n",
       " 'arcturian',\n",
       " 'area',\n",
       " 'arent',\n",
       " 'aretha',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'aria',\n",
       " 'arianna',\n",
       " 'ariel',\n",
       " 'aris',\n",
       " 'aristocraci',\n",
       " 'arizona',\n",
       " 'ark',\n",
       " 'arkansa',\n",
       " 'arm',\n",
       " 'armenia',\n",
       " 'armenian',\n",
       " 'armi',\n",
       " 'armstrong',\n",
       " 'arn',\n",
       " 'arnab',\n",
       " 'around',\n",
       " 'arquett',\n",
       " 'arrang',\n",
       " 'arrest',\n",
       " 'arriv',\n",
       " 'arrog',\n",
       " 'arsenal',\n",
       " 'arson',\n",
       " 'art',\n",
       " 'arteri',\n",
       " 'articl',\n",
       " 'artifact',\n",
       " 'artifici',\n",
       " 'artist',\n",
       " 'aryan',\n",
       " 'as',\n",
       " 'ascend',\n",
       " 'asda',\n",
       " 'ashton',\n",
       " 'ashutosh',\n",
       " 'asia',\n",
       " 'asid',\n",
       " 'ask',\n",
       " 'aspartam',\n",
       " 'ass',\n",
       " 'assad',\n",
       " 'assang',\n",
       " 'assangepilg',\n",
       " 'assasin',\n",
       " 'assassin',\n",
       " 'assault',\n",
       " 'assembl',\n",
       " 'assert',\n",
       " 'asset',\n",
       " 'assist',\n",
       " 'assistedsuicid',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'assur',\n",
       " 'asthm',\n",
       " 'astonish',\n",
       " 'astronaut',\n",
       " 'astronom',\n",
       " 'asylum',\n",
       " 'atf',\n",
       " 'atlanta',\n",
       " 'atlanti',\n",
       " 'atm',\n",
       " 'atroc',\n",
       " 'att',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attende',\n",
       " 'attent',\n",
       " 'attir',\n",
       " 'attitud',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'atttim',\n",
       " 'audaci',\n",
       " 'audienc',\n",
       " 'audio',\n",
       " 'auditor',\n",
       " 'aumf',\n",
       " 'aussi',\n",
       " 'australia',\n",
       " 'australian',\n",
       " 'austria',\n",
       " 'austrian',\n",
       " 'austyn',\n",
       " 'authent',\n",
       " 'author',\n",
       " 'authoritarian',\n",
       " 'autism',\n",
       " 'autist',\n",
       " 'auto',\n",
       " 'autom',\n",
       " 'automat',\n",
       " 'autonom',\n",
       " 'avail',\n",
       " 'aveng',\n",
       " 'averag',\n",
       " 'avert',\n",
       " 'aviv',\n",
       " 'avocado',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'awaken',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesom',\n",
       " 'awkward',\n",
       " 'awol',\n",
       " 'axelrod',\n",
       " 'axi',\n",
       " 'ayahuasca',\n",
       " 'ayatollah',\n",
       " 'ayott',\n",
       " 'az',\n",
       " 'baba',\n",
       " 'babi',\n",
       " 'babylon',\n",
       " 'back',\n",
       " 'backbon',\n",
       " 'backer',\n",
       " 'backfir',\n",
       " 'background',\n",
       " 'backlash',\n",
       " 'backlog',\n",
       " 'backout',\n",
       " 'backseat',\n",
       " 'backstori',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'badass',\n",
       " 'badasseri',\n",
       " 'bader',\n",
       " 'badg',\n",
       " 'badham',\n",
       " 'badtemp',\n",
       " 'baffl',\n",
       " 'bag',\n",
       " 'baghdad',\n",
       " 'bahaha',\n",
       " 'bahraini',\n",
       " 'baier',\n",
       " 'bail',\n",
       " 'bailout',\n",
       " 'bake',\n",
       " 'bakeri',\n",
       " 'balanc',\n",
       " 'baldfac',\n",
       " 'baldwin',\n",
       " 'balfour',\n",
       " 'balkan',\n",
       " 'ball',\n",
       " 'ballist',\n",
       " 'balloo',\n",
       " 'ballot',\n",
       " 'balochistan',\n",
       " 'baltic',\n",
       " 'baltimor',\n",
       " 'ban',\n",
       " 'banana',\n",
       " 'bancroft',\n",
       " 'bang',\n",
       " 'banish',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'bankrupt',\n",
       " 'banner',\n",
       " 'bannon',\n",
       " 'bar',\n",
       " 'barack',\n",
       " 'barag',\n",
       " 'barbar',\n",
       " 'barbara',\n",
       " 'barbarian',\n",
       " 'bare',\n",
       " 'bargain',\n",
       " 'barista',\n",
       " 'barney',\n",
       " 'barnstorm',\n",
       " 'baron',\n",
       " 'barrag',\n",
       " 'barrel',\n",
       " 'barrier',\n",
       " 'barter',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'bashar',\n",
       " 'basi',\n",
       " 'basic',\n",
       " 'basil',\n",
       " 'basket',\n",
       " 'batch',\n",
       " 'bathroom',\n",
       " 'baton',\n",
       " 'batteri',\n",
       " 'battl',\n",
       " 'battleground',\n",
       " 'battleship',\n",
       " 'bauer',\n",
       " 'bay',\n",
       " 'bayh',\n",
       " 'baylor',\n",
       " 'bbc',\n",
       " 'beammeupscotti',\n",
       " 'bean',\n",
       " 'bear',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beau',\n",
       " 'beaulieu',\n",
       " 'beauti',\n",
       " 'becam',\n",
       " 'beck',\n",
       " 'beckel',\n",
       " 'becom',\n",
       " 'bee',\n",
       " 'beef',\n",
       " 'beeley',\n",
       " 'beer',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'begin',\n",
       " 'begun',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behead',\n",
       " 'behind',\n",
       " 'bela',\n",
       " 'belarus',\n",
       " 'belgian',\n",
       " 'belgium',\n",
       " 'belief',\n",
       " 'believ',\n",
       " 'beliz',\n",
       " 'bella',\n",
       " 'belliger',\n",
       " 'belong',\n",
       " 'belt',\n",
       " 'beltway',\n",
       " 'ben',\n",
       " 'bend',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'bengaluru',\n",
       " 'benghazi',\n",
       " 'benjamin',\n",
       " 'benni',\n",
       " 'bergdahl',\n",
       " 'berkeley',\n",
       " 'berkley',\n",
       " 'berlin',\n",
       " 'bern',\n",
       " 'bernardino',\n",
       " 'berni',\n",
       " 'berniac',\n",
       " 'bernienom',\n",
       " 'berserk',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'betoota',\n",
       " 'betray',\n",
       " 'better',\n",
       " 'bev',\n",
       " 'bevin',\n",
       " 'bewar',\n",
       " 'beyonc',\n",
       " 'beyond',\n",
       " 'bezo',\n",
       " 'bias',\n",
       " 'bibi',\n",
       " 'bibl',\n",
       " 'biblic',\n",
       " 'bid',\n",
       " 'biden',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bigmoney',\n",
       " 'bigot',\n",
       " 'bigotri',\n",
       " 'bike',\n",
       " 'biker',\n",
       " 'bikini',\n",
       " 'bill',\n",
       " 'billari',\n",
       " 'billclinton',\n",
       " 'billion',\n",
       " 'billionair',\n",
       " 'bimbo',\n",
       " 'bin',\n",
       " 'bind',\n",
       " 'biolog',\n",
       " 'biometr',\n",
       " 'bionic',\n",
       " 'bipartisan',\n",
       " 'bird',\n",
       " 'birkenfeld',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'birther',\n",
       " 'birthplac',\n",
       " 'birthright',\n",
       " 'bishop',\n",
       " 'bison',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bitcoin',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'biz',\n",
       " 'bizarr',\n",
       " 'black',\n",
       " 'blackberri',\n",
       " 'blackhead',\n",
       " 'blackheart',\n",
       " 'blacklivesmatt',\n",
       " 'blackmail',\n",
       " 'blackout',\n",
       " 'blackwhit',\n",
       " 'blair',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'blanc',\n",
       " 'blanket',\n",
       " 'blasio',\n",
       " 'blasphem',\n",
       " 'blasphemi',\n",
       " 'blast',\n",
       " 'blatant',\n",
       " 'bleed',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blind',\n",
       " 'blindsid',\n",
       " 'blitz',\n",
       " 'blizzard',\n",
       " 'blm',\n",
       " 'blob',\n",
       " 'bloc',\n",
       " 'block',\n",
       " 'blockbust',\n",
       " 'blog',\n",
       " 'blogopen',\n",
       " 'blood',\n",
       " 'bloodbath',\n",
       " 'bloodi',\n",
       " 'bloomberg',\n",
       " 'bloombergback',\n",
       " 'blot',\n",
       " 'bloviat',\n",
       " 'blow',\n",
       " 'blowback',\n",
       " 'blowhard',\n",
       " 'blown',\n",
       " 'blowout',\n",
       " 'blu',\n",
       " 'blue',\n",
       " 'bluebeam',\n",
       " 'bluff',\n",
       " 'blunder',\n",
       " 'blunt',\n",
       " 'board',\n",
       " 'boast',\n",
       " 'boat',\n",
       " 'boati',\n",
       " 'bob',\n",
       " 'bobbi',\n",
       " 'bodden',\n",
       " 'bode',\n",
       " 'bodi',\n",
       " 'bodyguard',\n",
       " 'boehner',\n",
       " 'boil',\n",
       " 'boko',\n",
       " 'bold',\n",
       " 'bolivian',\n",
       " 'bollywood',\n",
       " 'bolster',\n",
       " 'bomb',\n",
       " 'bombard',\n",
       " 'bomber',\n",
       " 'bombshel',\n",
       " 'bond',\n",
       " 'bone',\n",
       " 'bonfir',\n",
       " 'bonni',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boobi',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'boom',\n",
       " 'boost',\n",
       " 'booth',\n",
       " 'booti',\n",
       " 'booz',\n",
       " 'border',\n",
       " 'bore',\n",
       " 'bori',\n",
       " 'borja',\n",
       " 'born',\n",
       " 'borromeo',\n",
       " 'bos',\n",
       " 'bosanski',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'botch',\n",
       " 'botox',\n",
       " 'bottom',\n",
       " 'bottomfish',\n",
       " 'bought',\n",
       " 'boulder',\n",
       " 'boulevard',\n",
       " 'bounc',\n",
       " 'boundless',\n",
       " 'bourgeoi',\n",
       " 'bow',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boxer',\n",
       " 'boy',\n",
       " 'boycott',\n",
       " 'boyfriend',\n",
       " 'boyl',\n",
       " 'brace',\n",
       " 'bradley',\n",
       " 'brag',\n",
       " 'brain',\n",
       " 'brainwash',\n",
       " 'braless',\n",
       " 'branch',\n",
       " 'brand',\n",
       " 'brandt',\n",
       " 'brave',\n",
       " 'braverman',\n",
       " 'brawl',\n",
       " 'brazen',\n",
       " 'brazil',\n",
       " 'breach',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breakingexclus',\n",
       " 'breakneck',\n",
       " 'breakout',\n",
       " 'breakthrough',\n",
       " 'breast',\n",
       " 'breath',\n",
       " 'breathtak',\n",
       " 'breitbart',\n",
       " 'breitbartgravi',\n",
       " 'bret',\n",
       " 'brew',\n",
       " 'breweri',\n",
       " 'brexit',\n",
       " 'brexittyp',\n",
       " 'brian',\n",
       " 'bribe',\n",
       " 'briberi',\n",
       " 'bric',\n",
       " 'brick',\n",
       " 'brickbat',\n",
       " 'bridg',\n",
       " 'brief',\n",
       " 'briefli',\n",
       " 'brigad',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'brilliant',\n",
       " 'brimelow',\n",
       " 'bring',\n",
       " 'brink',\n",
       " 'brinkmanship',\n",
       " 'bristl',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'briton',\n",
       " 'brittl',\n",
       " 'broad',\n",
       " 'broadcast',\n",
       " 'broaden',\n",
       " 'broadest',\n",
       " 'broccoli',\n",
       " 'broil',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'broker',\n",
       " 'bronx',\n",
       " 'brothel',\n",
       " 'brother',\n",
       " 'brotherhood',\n",
       " 'brotherjohnf',\n",
       " 'brought',\n",
       " 'broward',\n",
       " 'brown',\n",
       " 'bruce',\n",
       " 'bruis',\n",
       " 'brush',\n",
       " 'brussel',\n",
       " 'brutal',\n",
       " 'bryce',\n",
       " 'bubbl',\n",
       " 'bubl',\n",
       " 'buchanan',\n",
       " 'buck',\n",
       " 'buckley',\n",
       " 'budg',\n",
       " 'budget',\n",
       " 'budgetari',\n",
       " 'budweis',\n",
       " 'buffalo',\n",
       " 'buffett',\n",
       " 'bug',\n",
       " 'build',\n",
       " 'buildup',\n",
       " 'built',\n",
       " 'bulg',\n",
       " 'bull',\n",
       " 'bulldog',\n",
       " 'bullet',\n",
       " 'bulli',\n",
       " 'bullion',\n",
       " 'bum',\n",
       " 'bumbl',\n",
       " 'bumperstick',\n",
       " 'bundi',\n",
       " 'bungl',\n",
       " 'bunk',\n",
       " 'bunni',\n",
       " 'bure',\n",
       " 'bureau',\n",
       " 'burger',\n",
       " 'burglar',\n",
       " 'buri',\n",
       " 'burial',\n",
       " 'burka',\n",
       " 'burn',\n",
       " 'burnout',\n",
       " 'burnt',\n",
       " 'burst',\n",
       " 'bus',\n",
       " 'buse',\n",
       " 'bush',\n",
       " 'busi',\n",
       " 'bust',\n",
       " 'buster',\n",
       " 'butthurt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buzz',\n",
       " 'buzzfe',\n",
       " 'bypass',\n",
       " 'ca',\n",
       " 'cabal',\n",
       " 'cabin',\n",
       " 'cabinet',\n",
       " 'cabl',\n",
       " 'cach',\n",
       " 'cadet',\n",
       " 'cafe',\n",
       " 'cahil',\n",
       " 'cahoot',\n",
       " 'cair',\n",
       " 'caitlyn',\n",
       " 'cake',\n",
       " 'calai',\n",
       " 'calam',\n",
       " 'calcium',\n",
       " 'calcul',\n",
       " 'calendar',\n",
       " 'calif',\n",
       " 'california',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'cam',\n",
       " 'camden',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'cameron',\n",
       " 'camilla',\n",
       " 'camp',\n",
       " 'campaign',\n",
       " 'camper',\n",
       " 'campus',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancel',\n",
       " 'cancer',\n",
       " 'cancerlink',\n",
       " 'candac',\n",
       " 'candid',\n",
       " 'candidaci',\n",
       " 'cannabi',\n",
       " 'cannib',\n",
       " 'cano',\n",
       " 'canspam',\n",
       " 'cant',\n",
       " 'canter',\n",
       " 'cap',\n",
       " 'capabl',\n",
       " 'capit',\n",
       " 'capitan',\n",
       " 'capitol',\n",
       " 'capston',\n",
       " 'captiv',\n",
       " 'captur',\n",
       " 'car',\n",
       " 'carbon',\n",
       " 'carcinogen',\n",
       " 'card',\n",
       " 'cardin',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carey',\n",
       " 'cargo',\n",
       " 'caricatur',\n",
       " 'carl',\n",
       " 'carlo',\n",
       " 'carlzimm',\n",
       " 'carmel',\n",
       " 'carnag',\n",
       " 'carney',\n",
       " 'carol',\n",
       " 'carolina',\n",
       " 'carri',\n",
       " 'carrier',\n",
       " 'carrot',\n",
       " 'carson',\n",
       " 'cart',\n",
       " 'carter',\n",
       " 'cartoon',\n",
       " 'carv',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cashin',\n",
       " 'cashstrap',\n",
       " 'cast',\n",
       " ...]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_title_tfidf = pd.DataFrame(feature_matrix.toarray(), columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aap</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbi</th>\n",
       "      <th>abc</th>\n",
       "      <th>abcwapo</th>\n",
       "      <th>abduct</th>\n",
       "      <th>abdullah</th>\n",
       "      <th>abedin</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>...</th>\n",
       "      <th>zika</th>\n",
       "      <th>zimbabw</th>\n",
       "      <th>zion</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zip</th>\n",
       "      <th>zone</th>\n",
       "      <th>ztech</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuess</th>\n",
       "      <th>zulu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aap  abandon  abbi  abc  abcwapo  abduct  abdullah  abedin  abil  abl  ...  \\\n",
       "0  0.0      0.0   0.0  0.0      0.0     0.0       0.0     0.0   0.0  0.0  ...   \n",
       "1  0.0      0.0   0.0  0.0      0.0     0.0       0.0     0.0   0.0  0.0  ...   \n",
       "2  0.0      0.0   0.0  0.0      0.0     0.0       0.0     0.0   0.0  0.0  ...   \n",
       "3  0.0      0.0   0.0  0.0      0.0     0.0       0.0     0.0   0.0  0.0  ...   \n",
       "4  0.0      0.0   0.0  0.0      0.0     0.0       0.0     0.0   0.0  0.0  ...   \n",
       "\n",
       "   zika  zimbabw  zion  zionist  zip  zone  ztech  zuckerberg  zuess  zulu  \n",
       "0   0.0      0.0   0.0      0.0  0.0   0.0    0.0         0.0    0.0   0.0  \n",
       "1   0.0      0.0   0.0      0.0  0.0   0.0    0.0         0.0    0.0   0.0  \n",
       "2   0.0      0.0   0.0      0.0  0.0   0.0    0.0         0.0    0.0   0.0  \n",
       "3   0.0      0.0   0.0      0.0  0.0   0.0    0.0         0.0    0.0   0.0  \n",
       "4   0.0      0.0   0.0      0.0  0.0   0.0    0.0         0.0    0.0   0.0  \n",
       "\n",
       "[5 rows x 7176 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 f) - Most Frequent Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent words in \"real\" news within the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real = df.loc[df[\"label\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 634),\n",
       " ('clinton', 399),\n",
       " ('obama', 293),\n",
       " ('gop', 243),\n",
       " ('donald', 185),\n",
       " ('hillari', 184),\n",
       " ('debat', 167),\n",
       " ('republican', 163),\n",
       " ('new', 141),\n",
       " ('say', 138)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(\" \".join(df_real[\"title\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 15065),\n",
       " ('trump', 13904),\n",
       " ('clinton', 9705),\n",
       " ('state', 9410),\n",
       " ('would', 7747),\n",
       " ('republican', 7681),\n",
       " ('presid', 6377),\n",
       " ('say', 6338),\n",
       " ('one', 6203),\n",
       " ('peopl', 6055)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_real[\"text\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most frequent words in \"fake\" news within the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fake = df.loc[df[\"label\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 451),\n",
       " ('hillari', 398),\n",
       " ('clinton', 336),\n",
       " ('elect', 211),\n",
       " ('u', 200),\n",
       " ('new', 139),\n",
       " ('russia', 125),\n",
       " ('fbi', 122),\n",
       " ('video', 122),\n",
       " ('america', 115)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_fake[\"title\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('clinton', 6939),\n",
       " ('u', 6852),\n",
       " ('trump', 6515),\n",
       " ('peopl', 5478),\n",
       " ('state', 5402),\n",
       " ('one', 5203),\n",
       " ('would', 4895),\n",
       " ('hillari', 4516),\n",
       " ('like', 4101),\n",
       " ('elect', 4013)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(\" \".join(df_fake[\"text\"]).split()).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the labels to y to compare them with the predictions made by model\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "#function that compares different test_size splits and its result on multiple metric scores\n",
    "def func_classifier_metrics(classifier):\n",
    "    start = time.time()\n",
    "    print(\"-start-\")\n",
    "    for x in range(1, 10):\n",
    "        print(x)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_title_tfidf, y, test_size=x/10, random_state=2, shuffle=True)\n",
    "        classifier.fit(X_train ,y_train)\n",
    "        \n",
    "        pred_on_test_data = classifier.predict(X_test)\n",
    "        acc_score = accuracy_score(pred_on_test_data, y_test)\n",
    "        prec = precision_score(y_test.values, pred_on_test_data, pos_label=1)\n",
    "        recall = recall_score(y_test.values, pred_on_test_data)\n",
    "        f1 = f1_score(y_test.values, pred_on_test_data, average=\"binary\")\n",
    "        l_loss = log_loss(y_test.values, pred_on_test_data)\n",
    "        roc_auc = roc_auc_score(y_test.values, pred_on_test_data)\n",
    "        \n",
    "        print(\"Test size: \", x/10, \"| Accuracy: \", \"{0:.4f}\".format(acc_score), \"| Precision: \", \"{0:.4f}\".format(prec), \"| Recall: \", \"{0:.4f}\".format(recall), \"| F1: \", \"{0:.4f}\".format(f1), \"| ROC-AUC: \", \"{0:.4f}\".format(roc_auc), \"| Log. Loss: \", \"{0:.4f}\".format(l_loss))\n",
    "        x = x + 1\n",
    "    print(\"end of loop\")   \n",
    "    print(\"Time: {} mins\".format(round((time.time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 a) - Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-start-\n",
      "1\n",
      "Test size:  0.1 | Accuracy:  0.8044 | Precision:  0.8225 | Recall:  0.7700 | F1:  0.7954 | ROC-AUC:  0.8040 | Log. Loss:  6.7553\n",
      "2\n",
      "Test size:  0.2 | Accuracy:  0.8066 | Precision:  0.8407 | Recall:  0.7540 | F1:  0.7950 | ROC-AUC:  0.8063 | Log. Loss:  6.6788\n",
      "3\n",
      "Test size:  0.3 | Accuracy:  0.8085 | Precision:  0.8357 | Recall:  0.7607 | F1:  0.7964 | ROC-AUC:  0.8078 | Log. Loss:  6.6135\n",
      "4\n",
      "Test size:  0.4 | Accuracy:  0.7987 | Precision:  0.8344 | Recall:  0.7414 | F1:  0.7852 | ROC-AUC:  0.7983 | Log. Loss:  6.9514\n",
      "5\n",
      "Test size:  0.5 | Accuracy:  0.8081 | Precision:  0.8192 | Recall:  0.7778 | F1:  0.7980 | ROC-AUC:  0.8073 | Log. Loss:  6.6287\n",
      "6\n",
      "Test size:  0.6 | Accuracy:  0.7916 | Precision:  0.8016 | Recall:  0.7637 | F1:  0.7822 | ROC-AUC:  0.7911 | Log. Loss:  7.1968\n",
      "7\n",
      "Test size:  0.7 | Accuracy:  0.7781 | Precision:  0.8036 | Recall:  0.7312 | F1:  0.7657 | ROC-AUC:  0.7777 | Log. Loss:  7.6632\n",
      "8\n",
      "Test size:  0.8 | Accuracy:  0.7573 | Precision:  0.7772 | Recall:  0.7173 | F1:  0.7461 | ROC-AUC:  0.7571 | Log. Loss:  8.3826\n",
      "9\n",
      "Test size:  0.9 | Accuracy:  0.7262 | Precision:  0.7443 | Recall:  0.6870 | F1:  0.7145 | ROC-AUC:  0.7261 | Log. Loss:  9.4556\n",
      "end of loop\n",
      "Time: 0.07 mins\n"
     ]
    }
   ],
   "source": [
    "#Multinomial Naive Bayes\n",
    "#https://stats.stackexchange.com/questions/33185/difference-between-naive-bayes-multinomial-naive-bayes\n",
    "\n",
    "mNB = MultinomialNB()\n",
    "func_classifier_metrics(mNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-start-\n",
      "1\n",
      "Test size:  0.1 | Accuracy:  0.7950 | Precision:  0.8123 | Recall:  0.7604 | F1:  0.7855 | ROC-AUC:  0.7945 | Log. Loss:  7.0822\n",
      "2\n",
      "Test size:  0.2 | Accuracy:  0.8090 | Precision:  0.8464 | Recall:  0.7524 | F1:  0.7966 | ROC-AUC:  0.8087 | Log. Loss:  6.5970\n",
      "3\n",
      "Test size:  0.3 | Accuracy:  0.8059 | Precision:  0.8395 | Recall:  0.7489 | F1:  0.7916 | ROC-AUC:  0.8050 | Log. Loss:  6.7043\n",
      "4\n",
      "Test size:  0.4 | Accuracy:  0.7976 | Precision:  0.8432 | Recall:  0.7271 | F1:  0.7809 | ROC-AUC:  0.7970 | Log. Loss:  6.9923\n",
      "5\n",
      "Test size:  0.5 | Accuracy:  0.7973 | Precision:  0.8278 | Recall:  0.7377 | F1:  0.7801 | ROC-AUC:  0.7959 | Log. Loss:  6.9994\n",
      "6\n",
      "Test size:  0.6 | Accuracy:  0.7856 | Precision:  0.8171 | Recall:  0.7245 | F1:  0.7680 | ROC-AUC:  0.7844 | Log. Loss:  7.4058\n",
      "7\n",
      "Test size:  0.7 | Accuracy:  0.7709 | Precision:  0.8115 | Recall:  0.7008 | F1:  0.7521 | ROC-AUC:  0.7703 | Log. Loss:  7.9124\n",
      "8\n",
      "Test size:  0.8 | Accuracy:  0.7536 | Precision:  0.7853 | Recall:  0.6939 | F1:  0.7368 | ROC-AUC:  0.7532 | Log. Loss:  8.5121\n",
      "9\n",
      "Test size:  0.9 | Accuracy:  0.7287 | Precision:  0.7456 | Recall:  0.6919 | F1:  0.7178 | ROC-AUC:  0.7286 | Log. Loss:  9.3708\n",
      "end of loop\n",
      "Time: 0.12 mins\n"
     ]
    }
   ],
   "source": [
    "bNB = BernoulliNB()\n",
    "func_classifier_metrics(bNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-start-\n",
      "1\n",
      "Test size:  0.1 | Accuracy:  0.6719 | Precision:  0.7354 | Recall:  0.5240 | F1:  0.6119 | ROC-AUC:  0.6701 | Log. Loss:  11.3314\n",
      "2\n",
      "Test size:  0.2 | Accuracy:  0.6811 | Precision:  0.7522 | Recall:  0.5349 | F1:  0.6252 | ROC-AUC:  0.6803 | Log. Loss:  11.0132\n",
      "3\n",
      "Test size:  0.3 | Accuracy:  0.6860 | Precision:  0.7504 | Recall:  0.5427 | F1:  0.6299 | ROC-AUC:  0.6838 | Log. Loss:  10.8468\n",
      "4\n",
      "Test size:  0.4 | Accuracy:  0.6669 | Precision:  0.7162 | Recall:  0.5442 | F1:  0.6184 | ROC-AUC:  0.6660 | Log. Loss:  11.5039\n",
      "5\n",
      "Test size:  0.5 | Accuracy:  0.6689 | Precision:  0.7017 | Recall:  0.5576 | F1:  0.6214 | ROC-AUC:  0.6661 | Log. Loss:  11.4367\n",
      "6\n",
      "Test size:  0.6 | Accuracy:  0.6669 | Precision:  0.6943 | Recall:  0.5720 | F1:  0.6272 | ROC-AUC:  0.6650 | Log. Loss:  11.5039\n",
      "7\n",
      "Test size:  0.7 | Accuracy:  0.6773 | Precision:  0.7115 | Recall:  0.5875 | F1:  0.6436 | ROC-AUC:  0.6766 | Log. Loss:  11.1444\n",
      "8\n",
      "Test size:  0.8 | Accuracy:  0.6730 | Precision:  0.6961 | Recall:  0.6074 | F1:  0.6487 | ROC-AUC:  0.6727 | Log. Loss:  11.2927\n",
      "9\n",
      "Test size:  0.9 | Accuracy:  0.6526 | Precision:  0.6689 | Recall:  0.6004 | F1:  0.6328 | ROC-AUC:  0.6524 | Log. Loss:  11.9996\n",
      "end of loop\n",
      "Time: 0.23 mins\n"
     ]
    }
   ],
   "source": [
    "gNB = GaussianNB()\n",
    "func_classifier_metrics(gNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes seems to provide the best accuracy score with a test size of 0.2\n",
    "Accuracy:  0.8113654301499605"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 b) - Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#svc = SVC(gamma='auto', random_state=0)\n",
    "#svc = SVC(gamma=\"auto\")\n",
    "svc = SVC(gamma=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfunc_classifier_acc(svc)\\n'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "func_classifier_acc(svc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsvc = SVC(gamma=\"auto\")\\nfunc_classifier_acc(svc)\\n'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "svc = SVC(gamma=\"auto\")\n",
    "func_classifier_acc(svc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_test = SVC(gamma=\"scale\", C=1.5, kernel=\"poly\", degree=2, coef0=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.google.com/spreadsheets/d/1eSNWea1PujxDQeiwCEZZRcOWYB3lpEsqjekS0HRSUBw/edit#gid=0\n",
    "#func_classifier_metrics(svc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM with gamma=scale and a test size of 0.3 yielded in the highest accuracy:  0.8211467648605997"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 c) - Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.google.com/spreadsheets/d/1BBmq1wlc3AzKkBj5wE9EmoaM--XYjovsaVtyVbbHxes/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-start-\n",
      "1\n",
      "Test size:  0.1 | Accuracy:  0.7997 | Precision:  0.7688 | Recall:  0.8498 | F1:  0.8073 | ROC-AUC:  0.8003 | Log. Loss:  6.9188\n",
      "2\n",
      "Test size:  0.2 | Accuracy:  0.8122 | Precision:  0.7908 | Recall:  0.8460 | F1:  0.8175 | ROC-AUC:  0.8123 | Log. Loss:  6.4880\n",
      "3\n",
      "Test size:  0.3 | Accuracy:  0.8133 | Precision:  0.7868 | Recall:  0.8515 | F1:  0.8179 | ROC-AUC:  0.8138 | Log. Loss:  6.4500\n",
      "4\n",
      "Test size:  0.4 | Accuracy:  0.5576 | Precision:  0.5289 | Recall:  0.9889 | F1:  0.6892 | ROC-AUC:  0.5610 | Log. Loss:  15.2797\n",
      "5\n",
      "Test size:  0.5 | Accuracy:  0.8078 | Precision:  0.7828 | Recall:  0.8381 | F1:  0.8095 | ROC-AUC:  0.8085 | Log. Loss:  6.6396\n",
      "6\n",
      "Test size:  0.6 | Accuracy:  0.7919 | Precision:  0.7658 | Recall:  0.8287 | F1:  0.7960 | ROC-AUC:  0.7926 | Log. Loss:  7.1877\n",
      "7\n",
      "Test size:  0.7 | Accuracy:  0.7838 | Precision:  0.7609 | Recall:  0.8222 | F1:  0.7904 | ROC-AUC:  0.7841 | Log. Loss:  7.4686\n",
      "8\n",
      "Test size:  0.8 | Accuracy:  0.7707 | Precision:  0.7474 | Recall:  0.8138 | F1:  0.7792 | ROC-AUC:  0.7710 | Log. Loss:  7.9192\n",
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size:  0.9 | Accuracy:  0.7383 | Precision:  0.7130 | Recall:  0.7953 | F1:  0.7519 | ROC-AUC:  0.7385 | Log. Loss:  9.0376\n",
      "end of loop\n",
      "Time: 24.22 mins\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPClassifier(alpha=0.6, learning_rate=\"invscaling\")\n",
    "func_classifier_metrics(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 0.25 | Accuracy:  0.8232 | Precision:  0.7983 | Recall:  0.8613 | F1:  0.8286 | ROC-AUC:  0.8235 | Log. Loss:  6.1054\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8153603366649133\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(150,100,50), max_iter=300,activation = 'relu',solver='adam',random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.787480273540242\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_title_tfidf, y, test_size=0.3, random_state=2, shuffle=True)\n",
    "mlp.fit(X_train ,y_train)\n",
    "pred_on_test_data = mlp.predict(X_test)\n",
    "acc_score = accuracy_score(pred_on_test_data, y_test)\n",
    "print(acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 c) - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-start-\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size:  0.1 | Accuracy:  0.7839 | Precision:  0.7604 | Recall:  0.8211 | F1:  0.7896 | ROC-AUC:  0.7844 | Log. Loss:  7.4635\n",
      "2\n",
      "Test size:  0.2 | Accuracy:  0.7885 | Precision:  0.7855 | Recall:  0.7905 | F1:  0.7880 | ROC-AUC:  0.7885 | Log. Loss:  7.3058\n",
      "3\n",
      "Test size:  0.3 | Accuracy:  0.7901 | Precision:  0.7771 | Recall:  0.8045 | F1:  0.7906 | ROC-AUC:  0.7903 | Log. Loss:  7.2494\n",
      "4\n",
      "Test size:  0.4 | Accuracy:  0.7830 | Precision:  0.7751 | Recall:  0.7924 | F1:  0.7836 | ROC-AUC:  0.7830 | Log. Loss:  7.4967\n",
      "5\n",
      "Test size:  0.5 | Accuracy:  0.7835 | Precision:  0.7575 | Recall:  0.8174 | F1:  0.7863 | ROC-AUC:  0.7843 | Log. Loss:  7.4791\n",
      "6\n",
      "Test size:  0.6 | Accuracy:  0.7695 | Precision:  0.7431 | Recall:  0.8093 | F1:  0.7748 | ROC-AUC:  0.7703 | Log. Loss:  7.9601\n",
      "7\n",
      "Test size:  0.7 | Accuracy:  0.7504 | Precision:  0.7339 | Recall:  0.7790 | F1:  0.7558 | ROC-AUC:  0.7506 | Log. Loss:  8.6212\n",
      "8\n",
      "Test size:  0.8 | Accuracy:  0.7326 | Precision:  0.6996 | Recall:  0.8098 | F1:  0.7507 | ROC-AUC:  0.7331 | Log. Loss:  9.2346\n",
      "9\n",
      "Test size:  0.9 | Accuracy:  0.7048 | Precision:  0.6672 | Recall:  0.8139 | F1:  0.7333 | ROC-AUC:  0.7051 | Log. Loss:  10.1946\n",
      "end of loop\n",
      "Time: 0.48 mins\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "func_classifier_metrics(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-start-\n",
      "1\n",
      "Test size:  0.1 | Accuracy:  0.8139 | Precision:  0.7826 | Recall:  0.8626 | F1:  0.8207 | ROC-AUC:  0.8145 | Log. Loss:  6.4284\n",
      "2\n",
      "Test size:  0.2 | Accuracy:  0.7987 | Precision:  0.7713 | Recall:  0.8460 | F1:  0.8070 | ROC-AUC:  0.7990 | Log. Loss:  6.9515\n",
      "3\n",
      "Test size:  0.3 | Accuracy:  0.7991 | Precision:  0.7658 | Recall:  0.8526 | F1:  0.8069 | ROC-AUC:  0.7999 | Log. Loss:  6.9406\n",
      "4\n",
      "Test size:  0.4 | Accuracy:  0.7952 | Precision:  0.7662 | Recall:  0.8449 | F1:  0.8036 | ROC-AUC:  0.7956 | Log. Loss:  7.0741\n",
      "5\n",
      "Test size:  0.5 | Accuracy:  0.7951 | Precision:  0.7547 | Recall:  0.8588 | F1:  0.8034 | ROC-AUC:  0.7967 | Log. Loss:  7.0758\n",
      "6\n",
      "Test size:  0.6 | Accuracy:  0.7798 | Precision:  0.7350 | Recall:  0.8609 | F1:  0.7930 | ROC-AUC:  0.7814 | Log. Loss:  7.6057\n",
      "7\n",
      "Test size:  0.7 | Accuracy:  0.7698 | Precision:  0.7267 | Recall:  0.8586 | F1:  0.7872 | ROC-AUC:  0.7705 | Log. Loss:  7.9514\n",
      "8\n",
      "Test size:  0.8 | Accuracy:  0.7545 | Precision:  0.6968 | Recall:  0.8960 | F1:  0.7840 | ROC-AUC:  0.7554 | Log. Loss:  8.4781\n",
      "9\n",
      "Test size:  0.9 | Accuracy:  0.7183 | Precision:  0.6643 | Recall:  0.8797 | F1:  0.7570 | ROC-AUC:  0.7188 | Log. Loss:  9.7282\n",
      "end of loop\n",
      "Time: 5.83 mins\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=150)\n",
    "func_classifier_metrics(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-start-\n",
      "1\n",
      "Test size:  0.1 | Accuracy:  0.8044 | Precision:  0.7708 | Recall:  0.8594 | F1:  0.8127 | ROC-AUC:  0.8051 | Log. Loss:  6.7553\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-914eb15a6c54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mrfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfunc_classifier_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-61-10bc00821935>\u001b[0m in \u001b[0;36mfunc_classifier_metrics\u001b[1;34m(classifier)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_title_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mpred_on_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=1000)\n",
    "func_classifier_metrics(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=100, max_features=15)\n",
    "func_classifier_metrics(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 d) - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from time import time\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20, window=2, size=300, sample=6e-5, alpha=0.03, min_alpha=0.0007, negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(df[\"text\"], progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.train(df[\"text\"], total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.similar_by_word(\"clinton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"donald\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "y = np.array([1, 1, 2, 2])\n",
    "pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pd.pandas_profiling\n",
    "#pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mNB.fit(X_train ,y_train)\n",
    "\n",
    "#pred_on_test_data = mNB.predict(X_test)\n",
    "#acc_score = accuracy_score(pred_on_test_data, y_test)\n",
    "#print (\"Accuracy in percentage : \" , acc_score, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training data : \", len(X_train))\n",
    "print(\"Percentage of training data: \",len(X_train) * 100 / len(df), \"%\")\n",
    "print(\"----------------\")\n",
    "print(\"Number of training data : \", len(y_test))\n",
    "print(\"Percentage of training data: \",len(y_test) * 100 / len(df),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/FakeNews-(balanced)/fake_or_real_news_prepared.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this data set is well balanced, accuracy can be perceived as a reliable metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.sv-europe.com/crisp-dm-methodology/\n",
    "https://www.kaggle.com/aidenloe/data-understanding-using-python\n",
    "https://towardsdatascience.com/exploratory-data-analysis-in-python-c9a77dfa39ce\n",
    "https://towardsdatascience.com/exploratory-data-analysis-tutorial-in-python-15602b417445\n",
    "https://www.learndatasci.com/tutorials/python-pandas-tutorial-complete-introduction-for-beginners/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
